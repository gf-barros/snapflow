{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.dim_reduction failed: Traceback (most recent call last):\n",
      "  File \"/home/bombra/anaconda3/envs/padme/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/bombra/anaconda3/envs/padme/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/bombra/anaconda3/envs/padme/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/bombra/anaconda3/envs/padme/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 345, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/bombra/anaconda3/envs/padme/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/bombra/anaconda3/envs/padme/lib/python3.11/site-packages/IPython/extensions/autoreload.py\", line 305, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __init__() requires a code object with 1 free vars, not 0\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import safe_load, YAMLError\n",
    "from src.snapshots import snapshots_assembly\n",
    "from src.dim_reduction import SVD, AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parameters.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        params = safe_load(stream)\n",
    "    except YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'snapshots': {'file_type_str': 'h5_fenics',\n",
       "  'folder': 'data',\n",
       "  'file_name_contains': ['concentration'],\n",
       "  'dataset': None},\n",
       " 'svd': {'trunc_basis': 10,\n",
       "  'svd_type': 'randomized_svd',\n",
       "  'power_iterations': 1,\n",
       "  'oversampling': 20},\n",
       " 'auto_encoder': {'batch_size': 10,\n",
       "  'num_epochs': 10,\n",
       "  'learning_rate': '1e-4',\n",
       "  'weight_decay': '1e-8',\n",
       "  'loss_function': 'smooth_l1_loss',\n",
       "  'loss_parameters': {'beta': 0.2},\n",
       "  'num_workers': 2,\n",
       "  'number_of_hidden_layers': 5,\n",
       "  'hidden_layers_sizes': [50, 25, 12, 6, 3],\n",
       "  'hidden_layers_activation_function': ['leaky_relu',\n",
       "   'leaky_relu',\n",
       "   'leaky_relu',\n",
       "   'leaky_relu',\n",
       "   ''],\n",
       "  'hidden_layers_activation_function_parameters': [0.2, 0.2, 0.2, 0.2, 'None'],\n",
       "  'decoder_activation_function': 'sigmoid',\n",
       "  'decoder_activation_function_parameter': 'None'}}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70801, 2702)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(snapshots.shape)\n",
    "except:\n",
    "    filenames, snapshots = snapshots_assembly(params[\"snapshots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_params = {\n",
    "#     \"preprocessing_type\": \"min_max\",\n",
    "#     \"trunc_basis\": snapshots.shape[1],\n",
    "#     \"svd_type\": \"full_svd\",  # [\"full_svd\", \"randomized_svd\"]\n",
    "#     \"power_iterations\": 1,\n",
    "#     \"oversampling\": 20,\n",
    "# }\n",
    "\n",
    "# svd_step = SVD(snapshots, svd_params)\n",
    "# svd_step.fit()\n",
    "# svd_step.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshots_sample = snapshots[:500, :100]\n",
    "svd_step_randomized = SVD(snapshots_sample, params[\"svd\"])\n",
    "svd_step_randomized.fit()\n",
    "svd_step_randomized.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(svd_step_random.s[:220])\n",
    "# plt.plot(svd_step.s[:220], \"--\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ae = {}\n",
    "\n",
    "# ae_test = AutoEncoder(snapshots_sample, dict_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ae = {\n",
    "#     \"batch_size\": 10,\n",
    "#     \"num_epochs\": 10,\n",
    "#     \"num_workers\": 2,\n",
    "#     \"hidden_layer_size\": 50,\n",
    "#     \"latent_size\": 10,\n",
    "# }\n",
    "\n",
    "# ae_test_2 = AutoEncoderTrain(snapshots_sample, dict_ae)\n",
    "# ae_test_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ae = {\n",
    "#     \"batch_size\": 10,\n",
    "#     \"num_epochs\": 10,\n",
    "#     \"num_workers\": 2,\n",
    "#     \"number_of_hidden_layers\": 4,\n",
    "#     \"hidden_layers_sizes\": [50, 25, 12, 6],\n",
    "#     \"hidden_layers_activation_function\": [\"leaky_relu\", \"leaky_relu\", \"leaky_relu\", \"\"],\n",
    "#     \"hidden_layers_activation_function_parameters\": [0.2, 0.2, 0.2, None],\n",
    "#     \"decoder_activation_function\": \"sigmoid\",\n",
    "#     \"decoder_activation_function_parameter\": None,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(snapshots_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.2)\n",
      "  (2): Linear(in_features=50, out_features=25, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.2)\n",
      "  (4): Linear(in_features=25, out_features=12, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.2)\n",
      "  (6): Linear(in_features=12, out_features=6, bias=True)\n",
      "  (7): LeakyReLU(negative_slope=0.2)\n",
      "  (8): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=3, out_features=6, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.2)\n",
      "  (2): Linear(in_features=6, out_features=12, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.2)\n",
      "  (4): Linear(in_features=12, out_features=25, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.2)\n",
      "  (6): Linear(in_features=25, out_features=50, bias=True)\n",
      "  (7): LeakyReLU(negative_slope=0.2)\n",
      "  (8): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (9): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ae_test_2 = AutoEncoder(snapshots_sample, params[\"auto_encoder\"])\n",
    "ae_test_2.fit()\n",
    "\n",
    "print(ae_test_2.auto_encoder.encoder)\n",
    "print(ae_test_2.auto_encoder.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padme",
   "language": "python",
   "name": "padme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
