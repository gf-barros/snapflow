{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import safe_load, YAMLError\n",
    "from src.snapshots import snapshots_assembly\n",
    "from src.dim_reduction import SVD, AutoEncoderTrain, AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parameters.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        params = safe_load(stream)\n",
    "    except YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'snapshots': {'file_type_str': 'h5_fenics',\n",
       "  'folder': 'data',\n",
       "  'file_name_contains': ['concentration'],\n",
       "  'dataset': None}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 02:44:08,960 - src.snapshots - INFO - Starting choice of file type:\n",
      "2024-01-12 02:44:08,961 - src.snapshots - INFO - FEniCS HDF5 file selected.\n",
      "Loading Snapshots 2701: 100%|██████████| 2701/2701 [02:02<00:00, 22.12it/s]\n"
     ]
    }
   ],
   "source": [
    "filenames, snapshots = snapshots_assembly(params[\"snapshots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_params = {\n",
    "#     \"preprocessing_type\": \"min_max\",\n",
    "#     \"trunc_basis\": snapshots.shape[1],\n",
    "#     \"svd_type\": \"full_svd\",  # [\"full_svd\", \"randomized_svd\"]\n",
    "#     \"power_iterations\": 1,\n",
    "#     \"oversampling\": 20,\n",
    "# }\n",
    "\n",
    "# svd_step = SVD(snapshots, svd_params)\n",
    "# svd_step.fit()\n",
    "# svd_step.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_params = {\n",
    "    \"trunc_basis\": 10,\n",
    "    \"svd_type\": \"randomized_svd\",  # [\"full_svd\", \"randomized_svd\"]\n",
    "    \"power_iterations\": 1,\n",
    "    \"oversampling\": 20,\n",
    "}\n",
    "\n",
    "snapshots_sample = snapshots[:500, :100]\n",
    "svd_step_random = SVD(snapshots_sample, svd_params)\n",
    "svd_step_random.fit()\n",
    "svd_step_random.s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(svd_step_random.s[:220])\n",
    "# plt.plot(svd_step.s[:220], \"--\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ae = {}\n",
    "\n",
    "# ae_test = AutoEncoder(snapshots_sample, dict_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ae = {\n",
    "#     \"batch_size\": 10,\n",
    "#     \"num_epochs\": 10,\n",
    "#     \"num_workers\": 2,\n",
    "#     \"hidden_layer_size\": 50,\n",
    "#     \"latent_size\": 10,\n",
    "# }\n",
    "\n",
    "# ae_test_2 = AutoEncoderTrain(snapshots_sample, dict_ae)\n",
    "# ae_test_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ae = {\n",
    "    \"batch_size\": 10,\n",
    "    \"num_epochs\": 10,\n",
    "    \"num_workers\": 2,\n",
    "    \"number_of_hidden_layers\": 4,\n",
    "    \"hidden_layers_sizes\": [50, 25, 12, 6],\n",
    "    \"hidden_layers_activation_function\": [\"leaky_relu\", \"leaky_relu\", \"leaky_relu\", \"\"],\n",
    "    \"hidden_layers_activation_function_parameters\": [0.2, 0.2, 0.2, None],\n",
    "    \"decoder_activation_function\": \"sigmoid\",\n",
    "    \"decoder_activation_function_parameter\": None,\n",
    "}\n",
    "\n",
    "ae_test_2 = AutoEncoder(snapshots_sample, dict_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Linear(in_features=50, out_features=25, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.2)\n",
       "  (4): Linear(in_features=25, out_features=12, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.2)\n",
       "  (6): Linear(in_features=12, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_test_2.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=6, out_features=12, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Linear(in_features=12, out_features=25, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.2)\n",
       "  (4): Linear(in_features=25, out_features=50, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.2)\n",
       "  (6): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (7): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_test_2.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "ae_test_2 = AutoEncoderTrain(snapshots_sample, dict_ae)\n",
    "ae_test_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padme",
   "language": "python",
   "name": "padme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
