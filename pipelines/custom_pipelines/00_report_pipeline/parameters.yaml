origin_experiment_name: input #["input", "yaml"]
experiment_name: "test_surrogate_1"
local: False
random_state: 42
snapshots:
  file_type_str: 'h5_fenics' #h5_libmesh, h5_fenics
  folder: 'data/input'
  file_name_contains: ['concentration']
  dataset: null
splitting:
  strategy: "train_val" #["temporal", "kfold", "train_test", train_val]
  number_of_folds_or_splits: 5
  train_size: 0.8
  validation_size: 0.1
  test_size: 0.1
  gap: 0
normalization:
  snapshots: null
  svd: null
  auto_encoder: "min_max"
  surrogate: "min_max"
svd:
  trunc_basis: 270
  normalization: "min_max"
  svd_type: "full_svd"  # ["full_svd", "randomized_svd"]
  power_iterations: 1
  oversampling: 20
auto_encoder:
  data_loader: "data_loader"
  folder: 'data/models'
  data_loader_parameters:
    active: True
    parameters:
      batch_size: 64
      num_workers: 4
  num_epochs: 10
  initializer: "kaiming_normal"
  initializer_parameters:
    active: True
    parameters:
      mode: "fan_in"
      nonlinearity: "leaky_relu"
  optimizer: "adam"
  optimizer_parameters:
    active: True
    parameters:
      lr: 0.0001
      weight_decay: 0.00000001
  loss_function: "smooth_l1_loss"
  loss_function_parameters:
    active: True 
    parameters:
      beta: 0.2
  number_of_hidden_layers: 5
  hidden_layers_sizes: 
    0: 256
    1: 128
    2: 64
    3: 32
    4: 16
  hidden_layers_activation_function:
    0: "leaky_relu"
    1: "leaky_relu"
    2: "leaky_relu"
    3: "leaky_relu"
  hidden_layers_activation_function_parameters:
    active: 
      0 : True
      1 : True
      2 : True
      3 : True
    parameters:
      0 : 
        negative_slope : 0.2
      1 : 
        negative_slope : 0.2
      2 : 
        negative_slope : 0.2
      3 : 
        negative_slope : 0.2 
  decoder_activation_function: 
      0: "sigmoid"
  decoder_activation_function_parameters: 
    active: 
      0: False
    parameters:
      0: null
neural_network:
  folder: 'data/models'
  data_loader: "data_loader"
  data_loader_parameters:
    active: True
    parameters:
      batch_size: 64
      num_workers: 4
  num_epochs: 10
  initializer: "kaiming_normal"
  initializer_parameters:
    active: True
    parameters:
      mode: "fan_in"
      nonlinearity: "leaky_relu"
  optimizer: "adam"
  optimizer_parameters:
    active: True
    parameters: 
      lr: 0.005
  adaptive_learning_parameters:
    active: True
    parameters:
      step_size: 50
      gamma: 0.75
  loss_function: "mse_loss"
  loss_function_parameters: 
    active: False
    parameters: null
  num_workers: 2
  number_of_hidden_layers: 5
  hidden_layers_sizes: 
    0: 50
    1: 50
    2: 50
    3: 50
    4: 50
  hidden_layers_activation_function:
    0: "sigmoid"
    1: "sigmoid"
    2: "sigmoid"
    3: "sigmoid"
    4: "sigmoid"
  hidden_layers_activation_function_parameters:
    active: 
      0 : False
      1 : False
      2 : False
      3 : False
      4 : False
    parameters:
      0 : null
      1 : null
      2 : null 
      3 : null 
      4 : null
  output_layers_activation_function: 
      0: "sigmoid"
  output_layers_activation_function_parameters: 
    active: 
      0: False
    parameters:
      0: null
postprocessing:
  l2_error_in_sequence: 
    active: True
    clip: null
    line_plot_error: True
    bar_plot_error: False
    paraview_largest_error: True
    paraview_smallest_error: True
  paraview_specific_plot: null
  frobenius_error: True
  copy_log: True